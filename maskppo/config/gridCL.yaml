env_id: 'empty_dict'
config_path: 'maskppo/config'
algorithm_type: PPO  # SoftQ, PPO
total_timesteps: 100000
env_kwargs:
  n_actions: 8
  max_steps: 100
  simplify_action: False
  image_output: False
vec_env_kwargs: 'empty_dict'
is_atari: False
play_model: True
save_model: True
